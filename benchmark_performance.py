#!/usr/bin/env python3
"""
Benchmark de Performance Yukpo - GPU vs CPU
Test des objectifs : CrÃ©ation <5s, Recherche <2s
"""

import time
import requests
import json
import statistics
import sys
from typing import Dict, List, Tuple
import argparse

# Configuration
BACKEND_URL = "http://localhost:3001"
TEST_ITERATIONS = 10
VERBOSE = True

def log(message: str, level: str = "INFO"):
    """Logger simple avec timestamps"""
    if VERBOSE or level == "ERROR":
        timestamp = time.strftime("%H:%M:%S")
        print(f"[{timestamp}][{level}] {message}")

def test_service_creation(iteration: int = 1) -> Dict:
    """Test de crÃ©ation de service"""
    log(f"ğŸš€ Test crÃ©ation service #{iteration}")
    
    test_data = {
        "texte": f"Je vends mon ordinateur portable gaming RTX 4070 en excellent Ã©tat, utilisÃ© 6 mois. Processeur Intel i7, 32GB RAM, SSD 1TB. Prix nÃ©gociable. Test #{iteration}",
        "intention": "creation_service",
        "base64_image": []  # Pas d'image pour ce test de vitesse
    }
    
    start_time = time.time()
    
    try:
        response = requests.post(
            f"{BACKEND_URL}/api/ia/auto",
            json=test_data,
            headers={"Content-Type": "application/json"},
            timeout=30
        )
        
        end_time = time.time()
        elapsed_ms = (end_time - start_time) * 1000
        
        if response.status_code == 200:
            result = response.json()
            
            # VÃ©rifier les headers de performance
            tokens_consumed = response.headers.get('x-tokens-consumed', 'N/A')
            model_used = result.get('ia_model_used', 'unknown')
            
            success = True
            intention = result.get('intention', 'unknown')
            
            log(f"âœ… CrÃ©ation rÃ©ussie en {elapsed_ms:.0f}ms (tokens: {tokens_consumed}, modÃ¨le: {model_used})")
            
        else:
            log(f"âŒ Erreur HTTP {response.status_code}", "ERROR")
            success = False
            intention = "error"
            model_used = "none"
            
    except requests.exceptions.Timeout:
        end_time = time.time()
        elapsed_ms = (end_time - start_time) * 1000
        log(f"â° Timeout aprÃ¨s {elapsed_ms:.0f}ms", "ERROR")
        success = False
        intention = "timeout"
        model_used = "none"
        
    except Exception as e:
        end_time = time.time()
        elapsed_ms = (end_time - start_time) * 1000
        log(f"âŒ Erreur: {e} aprÃ¨s {elapsed_ms:.0f}ms", "ERROR")
        success = False
        intention = "error"
        model_used = "none"
    
    return {
        "iteration": iteration,
        "success": success,
        "elapsed_ms": elapsed_ms,
        "intention": intention,
        "model_used": model_used
    }

def test_cache_performance() -> Dict:
    """Test de performance du cache"""
    log("ğŸ§ª Test de performance du cache")
    
    # DonnÃ©es de test identiques pour tester le cache
    test_data = {
        "texte": "Je vends des vÃªtements pour enfants, boutique en ligne, livraison gratuite",
        "intention": "creation_service",
        "base64_image": []
    }
    
    results = []
    
    # Premier appel (pas de cache)
    log("ğŸ“ Premier appel (sans cache)")
    start_time = time.time()
    
    try:
        response = requests.post(
            f"{BACKEND_URL}/api/ia/auto",
            json=test_data,
            headers={"Content-Type": "application/json"},
            timeout=30
        )
        
        first_call_time = (time.time() - start_time) * 1000
        
        if response.status_code == 200:
            log(f"âœ… Premier appel rÃ©ussi en {first_call_time:.0f}ms")
            results.append(first_call_time)
        else:
            log(f"âŒ Premier appel Ã©chouÃ©: {response.status_code}", "ERROR")
            return {"error": "Premier appel Ã©chouÃ©"}
            
    except Exception as e:
        log(f"âŒ Erreur premier appel: {e}", "ERROR")
        return {"error": str(e)}
    
    # DeuxiÃ¨me appel (avec cache)
    log("âš¡ DeuxiÃ¨me appel (avec cache)")
    start_time = time.time()
    
    try:
        response = requests.post(
            f"{BACKEND_URL}/api/ia/auto",
            json=test_data,
            headers={"Content-Type": "application/json"},
            timeout=30
        )
        
        second_call_time = (time.time() - start_time) * 1000
        
        if response.status_code == 200:
            log(f"âœ… DeuxiÃ¨me appel rÃ©ussi en {second_call_time:.0f}ms")
            results.append(second_call_time)
        else:
            log(f"âŒ DeuxiÃ¨me appel Ã©chouÃ©: {response.status_code}", "ERROR")
            return {"error": "DeuxiÃ¨me appel Ã©chouÃ©"}
            
    except Exception as e:
        log(f"âŒ Erreur deuxiÃ¨me appel: {e}", "ERROR")
        return {"error": str(e)}
    
    # Calcul des amÃ©liorations
    if len(results) == 2:
        improvement = ((results[0] - results[1]) / results[0]) * 100
        speedup = results[0] / results[1] if results[1] > 0 else float('inf')
        
        log(f"ğŸ“Š AmÃ©lioration: {improvement:.1f}% plus rapide")
        log(f"ğŸ“Š AccÃ©lÃ©ration: {speedup:.1f}x plus rapide")
        
        return {
            "first_call_ms": results[0],
            "second_call_ms": results[1],
            "improvement_percent": improvement,
            "speedup_factor": speedup,
            "cache_working": results[1] < results[0] * 0.8  # 20% plus rapide = cache fonctionne
        }
    
    return {"error": "Pas assez de donnÃ©es"}

def test_multiple_requests(count: int = 5) -> List[Dict]:
    """Test de plusieurs requÃªtes pour mesurer la stabilitÃ©"""
    log(f"ğŸ”„ Test de {count} requÃªtes consÃ©cutives")
    
    results = []
    
    for i in range(1, count + 1):
        result = test_service_creation(i)
        results.append(result)
        
        # Pause entre les requÃªtes
        if i < count:
            time.sleep(1)
    
    return results

def analyze_performance(results: List[Dict]) -> Dict:
    """Analyse les rÃ©sultats de performance"""
    if not results:
        return {"error": "Aucun rÃ©sultat"}
    
    successful_results = [r for r in results if r["success"]]
    
    if not successful_results:
        return {"error": "Aucun test rÃ©ussi"}
    
    times = [r["elapsed_ms"] for r in successful_results]
    
    analysis = {
        "total_tests": len(results),
        "successful_tests": len(successful_results),
        "success_rate": (len(successful_results) / len(results)) * 100,
        "avg_time_ms": statistics.mean(times),
        "median_time_ms": statistics.median(times),
        "min_time_ms": min(times),
        "max_time_ms": max(times),
        "std_dev_ms": statistics.stdev(times) if len(times) > 1 else 0,
    }
    
    return analysis

def main():
    """Fonction principale de test"""
    log("ğŸš€ DÃ©marrage des tests de performance optimisÃ©s")
    
    # Test 1: Performance du cache
    log("\n" + "="*50)
    log("TEST 1: Performance du cache")
    cache_result = test_cache_performance()
    
    if "error" not in cache_result:
        log(f"âœ… Cache fonctionne: {cache_result['cache_working']}")
        if cache_result['cache_working']:
            log(f"ğŸ‰ AmÃ©lioration de {cache_result['improvement_percent']:.1f}% avec le cache!")
        else:
            log("âš ï¸ Cache ne semble pas fonctionner correctement")
    else:
        log(f"âŒ Erreur test cache: {cache_result['error']}", "ERROR")
    
    # Test 2: RequÃªtes multiples
    log("\n" + "="*50)
    log("TEST 2: RequÃªtes multiples")
    multiple_results = test_multiple_requests(3)
    
    # Analyse des rÃ©sultats
    log("\n" + "="*50)
    log("ANALYSE DES RÃ‰SULTATS")
    
    analysis = analyze_performance(multiple_results)
    
    if "error" not in analysis:
        log(f"ğŸ“Š Tests rÃ©ussis: {analysis['successful_tests']}/{analysis['total_tests']} ({analysis['success_rate']:.1f}%)")
        log(f"ğŸ“Š Temps moyen: {analysis['avg_time_ms']:.0f}ms")
        log(f"ğŸ“Š Temps mÃ©dian: {analysis['median_time_ms']:.0f}ms")
        log(f"ğŸ“Š Min/Max: {analysis['min_time_ms']:.0f}ms / {analysis['max_time_ms']:.0f}ms")
        
        # Ã‰valuation des performances
        if analysis['avg_time_ms'] < 5000:
            log("ğŸ‰ EXCELLENT: Temps moyen < 5s")
        elif analysis['avg_time_ms'] < 10000:
            log("âœ… BON: Temps moyen < 10s")
        elif analysis['avg_time_ms'] < 15000:
            log("âš ï¸ MOYEN: Temps moyen < 15s")
        else:
            log("âŒ LENT: Temps moyen > 15s")
    else:
        log(f"âŒ Erreur analyse: {analysis['error']}", "ERROR")
    
    log("\n" + "="*50)
    log("FIN DES TESTS")

if __name__ == "__main__":
    main() 